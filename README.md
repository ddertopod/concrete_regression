# Concrete Compressive Strength Regression (PyTorch)

Проект по прогнозированию прочности бетона (**Concrete Compressive Strength**)  
на основе открытого датасета UCI Machine Learning Repository.  
Модель реализована на **PyTorch**, данные автоматически скачиваются и обрабатываются.

---

## Структура проекта

```
concrete_regression/
├── config.py              # основные настройки и гиперпараметры
├── install.py             # скачивание и подготовка исходного датасета
├── preprocessing.py       # очистка и стандартизация данных, формирование train/test
├── dataset.py             # PyTorch Dataset для табличных данных
├── model.py               # MLP-регрессор
├── utils.py               # функции метрик и служебные утилиты
├── train.py               # обучение модели
├── evaluate.py            # оценка модели на test.csv
├── Makefile               # сценарии сборки (make install / make prep / make train / make eval)
├── requirements.txt       # зависимости Python
├── outputs/               # артефакты модели
└── data/                  # сюда скачиваются и сохраняются все данные

```

---

## Установка

```bash
# 1. Клонировать репозиторий и перейти в каталог проекта
cd concrete_regression

# 2. Установить зависимости
make start
```

---

## Подготовка данных

**Скачивание исходных данных:**
```bash
make install
```
Скрипт `install.py` автоматически скачивает архив и распаковывает его в папку `data/`, конвертирует `.xls → .xlsx`.

**Предобработка:**
```bash
make prep
```
- очищает пропуски, дубликаты и отрицательные значения  
- обрезает выбросы (нижний 1%, верхний 99%)  
- стандартизирует признаки (`StandardScaler`)  
- разбивает на **train.csv (80%)** и **test.csv (20%)**

---

## Обучение модели

```bash
make train
```

- Модель: **MLPRegressor** (многослойный персептрон)
- Функция потерь: `MSELoss`
- Оптимизатор: `Adam`
- Используется **AMP** (mixed precision) при наличии GPU
- Ранняя остановка по валидационному MSE
- Веса сохраняются в `outputs/best_model.pt`
- История обучения (`MAE, MAPE, WAPE, sMAPE, MSE, RMSE, R²`) — в `outputs/history.csv`

**Пример вывода:**
```
Epoch 050 | train: MSE 24.1520 RMSE 4.915 MAE 3.682 MAPE 13.27% WAPE 9.83% sMAPE 11.12% R² 0.901 |
             val:   MSE 26.3840 RMSE 5.137 MAE 3.740 MAPE 13.61% WAPE 10.12% sMAPE 11.41% R² 0.895
```

---

## Проверка на тестовых данных

```bash
make eval
```

Печатает итоговые метрики на **test.csv**:

```
TEST METRICS:
MAE    :   3.743
MAPE   :  13.471
WAPE   :  10.400
sMAPE  :  11.896
MSE    :  28.982
RMSE   :   5.383
R2     :   0.903
```

---

## Используемые метрики

| Метрика | Описание |
|----------|-----------|
| **MAE**   | Средняя абсолютная ошибка |
| **MAPE**  | Средняя абсолютная процентная ошибка |
| **WAPE**  | Взвешенная абсолютная процентная ошибка |
| **sMAPE** | Симметричная MAPE (устойчива к нулям) |
| **MSE**   | Среднеквадратичная ошибка |
| **RMSE**  | Корень из MSE |
| **R²**    | Коэффициент детерминации (насколько хорошо модель объясняет разброс данных) |

---

## Артефакты после обучения

| Файл | Назначение |
|------|-------------|
| `outputs/best_model.pt` | веса лучшей модели |
| `outputs/history.csv`   | история обучения (по эпохам и метрикам) |
| `outputs/metrics.json`  | итоговые метрики на валидации |
| `data/scaler.pkl`       | сохранённый `StandardScaler` для нормализации признаков |

---

## Системные требования

- Python ≥ 3.9  
- PyTorch ≥ 2.0  
- ОЗУ ≥ 4 ГБ (датасет небольшой, но стандартный питоновский стек требует памяти)

---

## Автор

**Софронов Марк @Ddertopod**  
